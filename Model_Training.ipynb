{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import *\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "import pickle\n",
    "from keras.callbacks import *\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from keras import regularizers\n",
    "from keras import models\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EventPrediction(object):\n",
    "\n",
    "    def __init__(self,window=3,filters=28,bch=25,epoch=20,train_test_split=0.8):\n",
    "        self.window=window\n",
    "        self.filters=filters\n",
    "        self.batch=bch\n",
    "        self.epc=epoch\n",
    "        self.mc=ModelCheckpoint(\"./checkpoints\"+\"weights.{epoch:02d}-loss{loss:.2f}-acc{acc:.2f}-.hdf5\", monitor='loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "        #self.es=EarlyStopping(monitor='loss', min_delta=1, patience=15, verbose=1, mode='auto')\n",
    "        self.tb=TensorBoard(log_dir='./logs',  batch_size=self.batch, write_graph=True, write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)\n",
    "        self.data=None\n",
    "        self.split=train_test_split\n",
    "        self.end=None\n",
    "        self.model=None\n",
    "\n",
    "    def load_data(self):\n",
    "        choice=input(\"Enter number to load dataset for-\\n1.large\\n2.mid\\n3.small\")\n",
    "        if(choice=='1'):\n",
    "            name='large'\n",
    "        elif(choice=='2'):\n",
    "            name='mid'\n",
    "        elif(choice=='3'):\n",
    "            name='small'\n",
    "        else:\n",
    "            raise(Exception(\"Invalid input\"))\n",
    "        with open(\"./small-new-lms_vec_training.pkl\",\"rb\")as f:\n",
    "            self.data=pickle.load(f)\n",
    "        self.end=int(len(self.data['Y'])*self.split)\n",
    "        \n",
    "    def f1_loss(self, y_true, y_pred):\n",
    "    \n",
    "        tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n",
    "        tn = K.sum(K.cast((1-y_true)*(1-y_pred), 'float'), axis=0)\n",
    "        fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n",
    "        fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n",
    "\n",
    "        p = tp / (tp + fp + K.epsilon())\n",
    "        r = tp / (tp + fn + K.epsilon())\n",
    "\n",
    "        f1 = 2*p*r / (p+r+K.epsilon())\n",
    "        f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n",
    "        return 1 - K.mean(f1)\n",
    "\n",
    "    def load_model(self):\n",
    "        longt=Input(shape=(28,),name='long')\n",
    "        medt=Input(shape=(28,),name='medium')\n",
    "        st=Input(shape=(None,28),name=\"short\")\n",
    "        \n",
    "        hist_ind = Input(shape=(10,1),name='historical_indicators')\n",
    "        \n",
    "        with open(\"./embedding_matrix.pkl\",\"rb\")as f:\n",
    "            embedding_matrix=pickle.load(f)\n",
    "        \n",
    "        std=Dropout(0.4)(st)\n",
    "        \n",
    "        lt0=Embedding(3913,100,weights=[embedding_matrix], input_length=28, trainable=False)(longt)\n",
    "        \n",
    "        lt1=Conv1D(self.filters, self.window, input_shape=(None,28),strides=1, padding='valid', dilation_rate=1, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(0.01), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(lt0)\n",
    "        \n",
    "        lt2=Conv1D(self.filters, 2,input_shape=(None,28), strides=1, padding='valid', dilation_rate=1, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(0.01), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(lt1)\n",
    "        \n",
    "        lt2d=Dropout(0.4)(lt2)\n",
    "        \n",
    "        mt0=Embedding(3913,100,weights=[embedding_matrix], input_length=28, trainable=False)(medt)\n",
    "        \n",
    "        mt1=Conv1D(self.filters, self.window, input_shape=(None,28),strides=1, padding='valid', dilation_rate=1, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(0.01), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(mt0)\n",
    "        \n",
    "        mt2=Conv1D(self.filters, 2,strides=1,input_shape=(None,28), padding='valid', dilation_rate=1, activation='relu', use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=regularizers.l2(0.01), bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None)(mt1)\n",
    "        \n",
    "        mt2d=Dropout(0.4)(mt2)\n",
    "        \n",
    "        ltoutput=GlobalMaxPooling1D()(lt2d)\n",
    "        mtoutput=GlobalMaxPooling1D()(mt2d)\n",
    "        stoutput=GlobalAveragePooling1D()(st)\n",
    "        \n",
    "        \n",
    "        feature=concatenate([ltoutput,mtoutput,stoutput])\n",
    "        h1=Dense(50,activation='relu')(feature)\n",
    "        h2=Dense(10,activation='relu')(h1)\n",
    "        \n",
    "        hind = LSTM(units = 50, return_sequences = True, input_shape = (10, 1))(hist_ind)\n",
    "        hind2d = Dropout(0.4)(hind)\n",
    "        tsoutput=GlobalMaxPooling1D()(hind2d)\n",
    "        \n",
    "        feature2=concatenate([h2,tsoutput])\n",
    "        h3=Dense(50,activation='relu')(feature2)\n",
    "        h4=Dense(10,activation='relu')(h3)\n",
    "        \n",
    "        trend=Dense(1,activation='sigmoid',name='class')(h4)\n",
    "        self.model=Model(inputs=[longt,medt,st,hist_ind],outputs=[trend])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         trend2=Dense(1,activation='sigmoid',name='class')(h4)\n",
    "#         self.model=Model(inputs=[hist_ind],outputs=[trend2])\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "        self.model.summary()\n",
    "\n",
    "    def load_saved_model(self):\n",
    "        files=os.listdir()\n",
    "        file_name=[i for i  in files if '.hdf5' in i]\n",
    "        print(\"Select the saved model to use -\")\n",
    "        for i,j in enumerate(file_name):\n",
    "            print(str(i+1)+\"-\"+j)\n",
    "        choice=input()\n",
    "        print(\"#\"*5+\"  Using saved model-\"+file_name[int(choice)-1]+\"  \"+\"#\"*5)\n",
    "        model=models.load_model(os.path.join(os.getcwd(),file_name[int(choice)-1]))\n",
    "        print(\"#\"*5+\"  Model Loaded  \"+\"#\"*5)\n",
    "        self.model=model\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        self.model.fit({\"long\":self.data['X']['long'][:self.end],\"medium\":self.data['X']['medium'][:self.end],\"short\":self.data['X']['short'][:self.end]},\n",
    "        {'class':self.data['Y'][:self.end]},epochs=self.epc,batch_size=self.batch,callbacks=None)\n",
    "\n",
    "    def test(self,data=None):\n",
    "        print(\"#\"*5+\"  Testing  \"+\"#\"*5)\n",
    "        if(data==None):\n",
    "            data=self.data\n",
    "        loss_metrics=self.model.evaluate({\"long\":data['X']['long'][self.end:],\"medium\":data['X']['medium'][self.end:],\"short\":data['X']['short'][self.end:]},\n",
    "        {'class':data['Y'][self.end:]},batch_size=1)\n",
    "        for i,j in enumerate(loss_metrics):\n",
    "            print(self.model.metrics_names[i],j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "long (InputLayer)               (None, 28)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "medium (InputLayer)             (None, 28)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 28, 100)      391300      long[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 28, 100)      391300      medium[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 26, 28)       8428        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 26, 28)       8428        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 25, 28)       1596        conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 25, 28)       1596        conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 25, 28)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 25, 28)       0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "short (InputLayer)              (None, None, 28)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 28)           0           dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 28)           0           dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 28)           0           short[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "historical_indicators (InputLay (None, 10, 1)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 84)           0           global_max_pooling1d_1[0][0]     \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "                                                                 global_average_pooling1d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 10, 50)       10400       historical_indicators[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 50)           4250        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 10, 50)       0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           510         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 50)           0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 60)           0           dense_2[0][0]                    \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 50)           3050        concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 10)           510         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "class (Dense)                   (None, 1)            11          dense_4[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 821,379\n",
      "Trainable params: 38,779\n",
      "Non-trainable params: 782,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "predict=EventPrediction()\n",
    "predict.load_data()\n",
    "predict.load_model()\n",
    "# predict.load_saved_model()\n",
    "predict.train()\n",
    "predict.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
