{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "names=[\"large\",\"mid\",\"small\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "glove_file = open('./glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('./news_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2438, 4)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_dates = list(df['date'])\n",
    "corpus = list(df['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_length = len(word_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_sentences = word_tokenizer.texts_to_sequences(corpus)\n",
    "# print(embedded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "word_count = lambda sentence: len(word_tokenize(sentence))\n",
    "longest_sentence = max(corpus, key=word_count)\n",
    "length_long_sentence = len(word_tokenize(longest_sentence))\n",
    "\n",
    "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_long_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2438"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(padded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedding_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"embedding_matrix.pkl\",\"wb\") as f:\n",
    "        pickle.dump(embedding_matrix,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./embedding_matrix.pkl\",\"rb\")as f:\n",
    "    matrix=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for i,date in enumerate(corpus_dates):\n",
    "    if date in data.keys():\n",
    "        data[date].append(padded_sentences[i])\n",
    "    else:\n",
    "        data[date] = [padded_sentences[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_vec={}\n",
    "# count=0\n",
    "for date in data:\n",
    "    temp=[]\n",
    "    for text in data[date]:\n",
    "#         doc=model(text)\n",
    "        temp.append(text)\n",
    "#map the vector mean to that day\n",
    "    if len(temp) > 1:\n",
    "        meank=np.mean(np.array(temp,dtype=np.float32),axis=0)\n",
    "    else:\n",
    "        meank = temp[0]\n",
    "    data_vec[date]=meank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2391,  100, 2392,    1, 2393,  897, 1127, 2394,  725,   58,   74,\n",
       "          6,    7,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vec['2011-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_vec\n",
    "with open(\"small-new-vec.pkl\",\"wb\") as f:\n",
    "        pickle.dump(data_vec,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the historical prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensex_data = pd.read_csv('BSESENSEX.csv',parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "# names=[\"large\",\"mid\",\"small\"]\n",
    "vectors={\"large\":None,\"mid\":None,\"small\":None}\n",
    "final_data={\"large\":None,\"mid\":None,\"small\":None}\n",
    "pricename={'large':'','mid':'mid','small':'small'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"small-new-vec.pkl\",\"rb\")as f:\n",
    "    vectors['small']=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1198"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectors['small'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2391,  100, 2392,    1, 2393,  897, 1127, 2394,  725,   58,   74,\n",
       "          6,    7,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0], dtype=int32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors['small']['2011-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data={}\n",
    "# df=pd.read_csv('./'+name+'-final.csv')\n",
    "df2=pd.read_csv(\"./nifty\"+pricename[name]+\"--50.csv\")\n",
    "price=df2.sort_values([\"date\"])\n",
    "sortdf=df.sort_values(['date'])\n",
    "\n",
    "change_price=[]\n",
    "# print(\"Setting up the change in price for \"+name)\n",
    "for i in range(len(price)-1):\n",
    "    change_price.append(1*(float(price.iloc[i+1]['Change-close'])>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "st=[]\n",
    "mt=[]\n",
    "lt=[]\n",
    "mapping={\"long\":lt,\"medium\":mt,\"short\":st}\n",
    "uniq_dt=price['date'].unique()\n",
    "for i in range(len(uniq_dt)):\n",
    "    #last but one since the next day is always for prediction.\n",
    "    if(i<len(uniq_dt)-1):\n",
    "        st.append(uniq_dt[i])\n",
    "        if(i-7>=0):\n",
    "            mt.append(uniq_dt[i-7:i])\n",
    "        else:\n",
    "            mt.append(uniq_dt[:i+1])\n",
    "        if(i-30>=0):\n",
    "            lt.append(uniq_dt[i-30:i])\n",
    "        else:\n",
    "            lt.append(uniq_dt[:i+1])\n",
    "# print(\"Doing for \"+name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#here term is for the time period, long, medium and short!\n",
    "for term in mapping:\n",
    "    count=0\n",
    "    for dat in mapping[term]:\n",
    "        temp=[]\n",
    "        if(type(dat)!=str):\n",
    "            for entry in dat:\n",
    "                try:\n",
    "                    temp.append(vectors[name][entry])\n",
    "                except Exception as e:\n",
    "                    pass\n",
    "            if(len(temp)!=0):\n",
    "                if term in final_data.keys():\n",
    "                    final_data[term].append(np.array(temp))\n",
    "                else:\n",
    "                    final_data[term] = [np.array(temp)]\n",
    "            else:\n",
    "                if term in final_data.keys():\n",
    "                    final_data[term].append(np.zeros(28))\n",
    "                else:\n",
    "                    final_data[term] = [np.zeros(28)]\n",
    "#                 final_data[term].append(np.zeros(28))\n",
    "        else:\n",
    "            try:\n",
    "                if term in final_data.keys():\n",
    "                    final_data[term].append(vectors[name][dat])\n",
    "                else:\n",
    "                    final_data[term] = [vectors[name][dat]]\n",
    "#                 final_data[term].append(vectors[name][dat])\n",
    "            except Exception as e:\n",
    "                if term in final_data.keys():\n",
    "                    final_data[term].append(np.zeros(28))\n",
    "                else:\n",
    "                    final_data[term] = [np.zeros(28)]\n",
    "#                 final_data[term].append(np.zeros(28))\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing all vectors to same size for small long\n",
      "Resizing all vectors to same size for small medium\n",
      "Resizing all vectors to same size for small short\n",
      "Shapes after resize\n",
      " for long-(1672, 30, 28)\n",
      " for medium-(1672, 7, 28)\n",
      " for short-(1672, 1, 28)\n",
      "Length of the change in price 1672\n",
      "done for small\n",
      "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-\n",
      "Pre processing done !\n"
     ]
    }
   ],
   "source": [
    "for term in ['long','medium','short']:\n",
    "    if(term=='long'):\n",
    "        wall=30\n",
    "    elif(term=='medium'):\n",
    "        wall=7\n",
    "    else:\n",
    "        wall=1\n",
    "    print(\"Resizing all vectors to same size for \"  +name+\" \"+term)\n",
    "    for dat in range(len(final_data[term])):\n",
    "        ref=len(final_data[term][dat])\n",
    "        if(ref==28):\n",
    "            final_data[term][dat]=np.zeros((wall,28))\n",
    "            continue\n",
    "        else:\n",
    "            if(wall-ref>0):\n",
    "                final_data[term][dat]=np.vstack((final_data[term][dat],np.zeros((wall-ref,28))))\n",
    "print(\"Shapes after resize\")\n",
    "for term in final_data:\n",
    "    final_data[term]=np.array(final_data[term])\n",
    "    print(\" for \"+term+\"-\"+str(final_data[term].shape))\n",
    "print(\"Length of the change in price\",len(change_price))\n",
    "dt={\"X\":final_data,\"Y\":np.array(change_price)}\n",
    "with open(\"small-new-lms_vec_training.pkl\",\"wb\")as f:\n",
    "    pickle.dump(dt,f)\n",
    "print(\"done for \"+name)\n",
    "print(\"#-\"*15)\n",
    "print(\"Pre processing done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
