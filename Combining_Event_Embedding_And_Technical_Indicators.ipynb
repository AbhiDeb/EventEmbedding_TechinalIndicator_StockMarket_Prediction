{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up the change in price for large\n",
      "Merging data for same date for large\n",
      "argument of type 'float' is not iterable\n",
      "argument of type 'float' is not iterable\n",
      "argument of type 'float' is not iterable\n",
      "Doing for large\n",
      "Resizing all vectors to same size for large long\n",
      "Resizing all vectors to same size for large medium\n",
      "Resizing all vectors to same size for large short\n",
      "Shapes after resize\n",
      " for long-(1646, 30, 300)\n",
      " for medium-(1646, 7, 300)\n",
      " for short-(1646, 1, 300)\n",
      "Length of the change in price for large 1646\n",
      "done for large\n",
      "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-\n",
      "Setting up the change in price for mid\n",
      "Merging data for same date for mid\n",
      "Doing for mid\n",
      "Resizing all vectors to same size for mid long\n",
      "Resizing all vectors to same size for mid medium\n",
      "Resizing all vectors to same size for mid short\n",
      "Shapes after resize\n",
      " for long-(1627, 30, 300)\n",
      " for medium-(1627, 7, 300)\n",
      " for short-(1627, 1, 300)\n",
      "Length of the change in price for mid 1627\n",
      "done for mid\n",
      "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-\n",
      "Setting up the change in price for small\n",
      "Merging data for same date for small\n",
      "Doing for small\n",
      "Resizing all vectors to same size for small long\n",
      "Resizing all vectors to same size for small medium\n",
      "Resizing all vectors to same size for small short\n",
      "Shapes after resize\n",
      " for long-(1672, 30, 300)\n",
      " for medium-(1672, 7, 300)\n",
      " for short-(1672, 1, 300)\n",
      "Length of the change in price for small 1672\n",
      "done for small\n",
      "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-\n",
      "Pre processing done !\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pickle\n",
    "import spacy\n",
    "import numpy as np\n",
    "names=[\"large\",\"mid\",\"small\"]\n",
    "vectors={\"large\":None,\"mid\":None,\"small\":None}\n",
    "final_data={\"large\":None,\"mid\":None,\"small\":None}\n",
    "pricename={'large':'','mid':'mid','small':'small'}\n",
    "for name in vectors:\n",
    "    with open(name+\"-vec.pkl\",\"rb\")as f:\n",
    "        vectors[name]=pickle.load(f)\n",
    "for name in names:\n",
    "    final_data[name]={\"long\":[],\"medium\":[],\"short\":[]}\n",
    "    df=pd.read_csv('./'+name+'-final.csv')\n",
    "    df2=pd.read_csv(\"./nifty\"+pricename[name]+\"--50.csv\")\n",
    "    price=df2.sort_values([\"date\"])\n",
    "    sortdf=df.sort_values(['date'])\n",
    "    # makes all news of same date mapped to its corresponding date\n",
    "    data={}\n",
    "    corrpt={}\n",
    "    #creates y train/test\n",
    "    change_price=[]\n",
    "    print(\"Setting up the change in price for \"+name)\n",
    "    for i in range(len(price)-1):\n",
    "        change_price.append(1*(float(price.iloc[i+1]['Change-close'])>0))\n",
    "    print(\"Merging data for same date for \"+name)\n",
    "    for i in range(len(sortdf)):\n",
    "        temp=[]\n",
    "        if(data.get(sortdf.iloc[i]['date'],None)==None):\n",
    "            data[sortdf.iloc[i]['date']]=[]\n",
    "        temp.append(str(sortdf.iloc[i]['data']).strip(\"\\n\"))\n",
    "        try:\n",
    "            if('http' not in sortdf.iloc[i]['url'] ):\n",
    "                try:\n",
    "                    corrpt[sortdf.iloc[i]['date']].append(sortdf.iloc[i]['url'])\n",
    "                    temp.append(str(sortdf.iloc[i]['url']).strip(\"\\n\"))\n",
    "                except:\n",
    "                    corrpt[sortdf.iloc[i]['date']]=[]\n",
    "                    corrpt[sortdf.iloc[i]['date']].append(sortdf.iloc[i]['url'].rstrip(\"\\n\"))\n",
    "                    temp.append(str(sortdf.iloc[i]['url']).strip(\"\\n\"))\n",
    "        #The data is already added before , so nothing to worry about.\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        data[sortdf.iloc[i]['date']].append(' '.join(temp))\n",
    "    \n",
    "    for i in data:\n",
    "        data[i]=set(data[i])\n",
    "    st=[]\n",
    "    mt=[]\n",
    "    lt=[]\n",
    "    mapping={\"long\":lt,\"medium\":mt,\"short\":st}\n",
    "    uniq_dt=price['date'].unique()\n",
    "    for i in range(len(uniq_dt)):\n",
    "        #last but one since the next day is always for prediction.\n",
    "        if(i<len(uniq_dt)-1):\n",
    "            st.append(uniq_dt[i])\n",
    "            if(i-7>=0):\n",
    "                mt.append(uniq_dt[i-7:i])\n",
    "            else:\n",
    "                mt.append(uniq_dt[:i+1])\n",
    "            if(i-30>=0):\n",
    "                lt.append(uniq_dt[i-30:i])\n",
    "            else:\n",
    "                lt.append(uniq_dt[:i+1])\n",
    "    print(\"Doing for \"+name)\n",
    "    \n",
    "    #here term is for the time period, long, medium and short!\n",
    "    for term in mapping:\n",
    "        count=0\n",
    "        for dat in mapping[term]:\n",
    "            temp=[]\n",
    "            if(type(dat)!=str):\n",
    "                for entry in dat:\n",
    "                    try:\n",
    "                        temp.append(vectors[name][entry])\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "                if(len(temp)!=0):\n",
    "                    final_data[name][term].append(np.array(temp))\n",
    "                else:\n",
    "                    final_data[name][term].append(np.zeros(300))\n",
    "            else:\n",
    "                try:\n",
    "                    final_data[name][term].append(vectors[name][dat])\n",
    "                except Exception as e:\n",
    "                    final_data[name][term].append(np.zeros(300))\n",
    "            count+=1\n",
    "\n",
    "    for term in ['long','medium','short']:\n",
    "        if(term=='long'):\n",
    "            wall=30\n",
    "        elif(term=='medium'):\n",
    "            wall=7\n",
    "        else:\n",
    "            wall=1\n",
    "        print(\"Resizing all vectors to same size for \"  +name+\" \"+term)\n",
    "        for dat in range(len(final_data[name][term])):\n",
    "            ref=len(final_data[name][term][dat])\n",
    "            if(ref==300):\n",
    "                final_data[name][term][dat]=np.zeros((wall,300))\n",
    "                continue\n",
    "            else:\n",
    "                if(wall-ref>0):\n",
    "                    final_data[name][term][dat]=np.vstack((final_data[name][term][dat],np.zeros((wall-ref,300))))\n",
    "    print(\"Shapes after resize\")\n",
    "    for term in final_data[name]:\n",
    "        final_data[name][term]=np.array(final_data[name][term])\n",
    "        print(\" for \"+term+\"-\"+str(final_data[name][term].shape))\n",
    "    print(\"Length of the change in price for \"+name,len(change_price))\n",
    "    dt={\"X\":final_data[name],\"Y\":np.array(change_price)}\n",
    "    with open(name+\"-lms_vec_training.pkl\",\"wb\")as f:\n",
    "        pickle.dump(dt,f)\n",
    "    print(\"done for \"+name)\n",
    "    print(\"#-\"*15)\n",
    "print(\"Pre processing done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
